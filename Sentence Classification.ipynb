{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/datasets/imdb.py:45: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17448960/17464789 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "top_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 1\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n",
      "141\n",
      "550\n",
      "147\n",
      "43\n",
      "123\n",
      "562\n",
      "233\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "for a in X_train[:10]:\n",
    "    print (len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 1600\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ...,  19 178  32] 1600\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0], len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(16, 3, padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Convolution1D(16, 3, border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(180,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 1828s - loss: 0.3933 - acc: 0.8152  \n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 1802s - loss: 0.1505 - acc: 0.9466  \n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 1913s - loss: 0.0480 - acc: 0.9834  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d4448f278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=3, verbose = 1, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.465346926227\n",
      "Test accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test[:100], y_test[:100], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1600, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1600, 64)          57664     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1600, 32)          6176      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1600, 16)          1552      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 180)               4608180   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 7,673,753\n",
      "Trainable params: 7,673,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, merge\n",
    "query = Input(shape = (1600, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(top_words, embedding_vector_length, input_length=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_e = e(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=/input_1, outputs=Reshape{3}...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_tmp = Model(input = query, output = out_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp.compile(optimizer = \"adadelta\", loss = \"binary_crossentropy\")\n",
    "from keras import backend\n",
    "\n",
    "get_repr = backend.function([query], out_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr = get_repr([X_train[0].reshape(1600,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ...,  19, 178,  32], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04689165,  0.00164434, -0.0414691 , -0.01268752,  0.01458974,\n",
       "         0.0194481 , -0.01376501, -0.00874614,  0.0016255 ,  0.01300043,\n",
       "         0.00913168, -0.03762851,  0.04514131,  0.00753866,  0.0113394 ,\n",
       "         0.01148813, -0.04490088, -0.0014638 , -0.04716635,  0.03980613,\n",
       "        -0.00968654, -0.03714398, -0.00895769, -0.00449478, -0.00194495,\n",
       "        -0.01090954, -0.03410237,  0.0360073 , -0.02807523,  0.04654723,\n",
       "        -0.04427888, -0.03530645, -0.04637638,  0.04398745,  0.04276075,\n",
       "        -0.01069003, -0.00922956,  0.0437774 , -0.01333702, -0.04761531,\n",
       "         0.04720573,  0.00678061, -0.02969839,  0.02867307, -0.03363846,\n",
       "        -0.04719247,  0.03243979, -0.0342715 ,  0.03748943, -0.00708717,\n",
       "        -0.00425385, -0.00998966, -0.03635811,  0.0221416 , -0.00365049,\n",
       "        -0.02227639, -0.03176845,  0.01458277, -0.0209214 , -0.04383406,\n",
       "        -0.01147091,  0.03769008,  0.03926635,  0.02770606,  0.04895506,\n",
       "        -0.01544254,  0.00985148,  0.02622911, -0.02700772,  0.03037553,\n",
       "         0.00406811,  0.04084028,  0.03272146,  0.00350637, -0.04239241,\n",
       "        -0.03942604, -0.02675729, -0.01212666, -0.02982791,  0.01572629,\n",
       "         0.00135317, -0.00029312, -0.01088952,  0.03393654,  0.02562014,\n",
       "         0.04858885, -0.03018533,  0.02357718,  0.04915995, -0.02685991,\n",
       "        -0.0327816 ,  0.03391164,  0.0088299 ,  0.02999485,  0.02976233,\n",
       "         0.04674663,  0.01372284, -0.04927788, -0.00669535, -0.00972441,\n",
       "         0.00711863, -0.02043085, -0.04122476, -0.04607256,  0.02060084,\n",
       "        -0.03263855,  0.01247627,  0.02173897,  0.04881051,  0.00840901,\n",
       "        -0.03614239, -0.01644664, -0.03500575, -0.02642793,  0.04334614,\n",
       "        -0.02428522, -0.02373155,  0.029843  , -0.03471977,  0.04297612,\n",
       "         0.00889803, -0.00434884,  0.01543911,  0.04671165,  0.04867929,\n",
       "         0.02454106, -0.02238688, -0.03905508, -0.01849584,  0.00274706,\n",
       "        -0.01952049,  0.04168229, -0.02153583, -0.02907694, -0.0420514 ,\n",
       "         0.04549034,  0.00587937,  0.03618604, -0.0236129 , -0.03495177,\n",
       "         0.0091994 ,  0.03392631, -0.03665358,  0.03108261, -0.02084528,\n",
       "        -0.03373479, -0.00706956, -0.02570588,  0.02266008, -0.02969061,\n",
       "         0.02595937,  0.02032509, -0.03592053,  0.01637336, -0.04827378,\n",
       "         0.00764459,  0.01267937, -0.00448838, -0.0325127 , -0.01432237,\n",
       "         0.00160727,  0.03432782, -0.01970552,  0.01249082,  0.01468836,\n",
       "         0.04735121,  0.02259797,  0.03623551, -0.00260303,  0.0366354 ,\n",
       "         0.01479185,  0.0155664 , -0.04474191, -0.02006251,  0.00581194,\n",
       "         0.01952538,  0.02831635,  0.03669049,  0.00672931,  0.00913335,\n",
       "        -0.00223316,  0.00901038,  0.01866506,  0.04346972,  0.00764959,\n",
       "         0.01033017,  0.0409821 , -0.01484726, -0.00455476, -0.02377777,\n",
       "        -0.0215332 , -0.02067644,  0.0035886 , -0.0211627 ,  0.03879642,\n",
       "         0.04559758, -0.04595903, -0.04326691, -0.01134912, -0.00917543,\n",
       "         0.01986353,  0.03098044,  0.01275226,  0.04678649, -0.02802868,\n",
       "        -0.03410622,  0.00540535,  0.00628532,  0.00984391,  0.03186729,\n",
       "         0.04683668,  0.01153338,  0.02733256, -0.02791614, -0.02467622,\n",
       "         0.00906469,  0.0153342 , -0.03887607, -0.04312692,  0.00426116,\n",
       "         0.04921346,  0.02979599, -0.03631207, -0.02175195,  0.01426172,\n",
       "        -0.03755216, -0.00724949, -0.02862892, -0.00825327, -0.02905211,\n",
       "         0.03964726, -0.03609635, -0.04612649, -0.03062508,  0.04731439,\n",
       "         0.03181446,  0.03941695,  0.0222747 ,  0.0406341 ,  0.02655804,\n",
       "        -0.03137461,  0.04743605, -0.04258213,  0.04822705,  0.00250825,\n",
       "         0.03504071,  0.03280984,  0.03816792,  0.04004583, -0.00422833,\n",
       "        -0.00214538, -0.02057733, -0.00049534, -0.01692481, -0.02620867,\n",
       "        -0.04685687,  0.00073973, -0.04951539,  0.00138189, -0.03196437,\n",
       "         0.01526209, -0.02535561,  0.04447925,  0.03282114,  0.02715973,\n",
       "        -0.04646251, -0.00487036, -0.04022205,  0.04160831, -0.04199401,\n",
       "        -0.01563377, -0.04513487,  0.00544341, -0.04899332, -0.00502171,\n",
       "         0.04055027, -0.04766341,  0.00744171, -0.01586037,  0.04484962,\n",
       "        -0.0060848 , -0.03644824, -0.00015423,  0.02194009,  0.01273659,\n",
       "        -0.01225598,  0.01387631, -0.01624237, -0.0034321 ,  0.00502386,\n",
       "        -0.00729952,  0.02679081, -0.04998935, -0.04166021,  0.01380208,\n",
       "        -0.0164511 , -0.02107395, -0.04593343, -0.01402203,  0.04411262]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04689165,  0.00164434, -0.0414691 , -0.01268752,  0.01458974,\n",
       "         0.0194481 , -0.01376501, -0.00874614,  0.0016255 ,  0.01300043,\n",
       "         0.00913168, -0.03762851,  0.04514131,  0.00753866,  0.0113394 ,\n",
       "         0.01148813, -0.04490088, -0.0014638 , -0.04716635,  0.03980613,\n",
       "        -0.00968654, -0.03714398, -0.00895769, -0.00449478, -0.00194495,\n",
       "        -0.01090954, -0.03410237,  0.0360073 , -0.02807523,  0.04654723,\n",
       "        -0.04427888, -0.03530645, -0.04637638,  0.04398745,  0.04276075,\n",
       "        -0.01069003, -0.00922956,  0.0437774 , -0.01333702, -0.04761531,\n",
       "         0.04720573,  0.00678061, -0.02969839,  0.02867307, -0.03363846,\n",
       "        -0.04719247,  0.03243979, -0.0342715 ,  0.03748943, -0.00708717,\n",
       "        -0.00425385, -0.00998966, -0.03635811,  0.0221416 , -0.00365049,\n",
       "        -0.02227639, -0.03176845,  0.01458277, -0.0209214 , -0.04383406,\n",
       "        -0.01147091,  0.03769008,  0.03926635,  0.02770606,  0.04895506,\n",
       "        -0.01544254,  0.00985148,  0.02622911, -0.02700772,  0.03037553,\n",
       "         0.00406811,  0.04084028,  0.03272146,  0.00350637, -0.04239241,\n",
       "        -0.03942604, -0.02675729, -0.01212666, -0.02982791,  0.01572629,\n",
       "         0.00135317, -0.00029312, -0.01088952,  0.03393654,  0.02562014,\n",
       "         0.04858885, -0.03018533,  0.02357718,  0.04915995, -0.02685991,\n",
       "        -0.0327816 ,  0.03391164,  0.0088299 ,  0.02999485,  0.02976233,\n",
       "         0.04674663,  0.01372284, -0.04927788, -0.00669535, -0.00972441,\n",
       "         0.00711863, -0.02043085, -0.04122476, -0.04607256,  0.02060084,\n",
       "        -0.03263855,  0.01247627,  0.02173897,  0.04881051,  0.00840901,\n",
       "        -0.03614239, -0.01644664, -0.03500575, -0.02642793,  0.04334614,\n",
       "        -0.02428522, -0.02373155,  0.029843  , -0.03471977,  0.04297612,\n",
       "         0.00889803, -0.00434884,  0.01543911,  0.04671165,  0.04867929,\n",
       "         0.02454106, -0.02238688, -0.03905508, -0.01849584,  0.00274706,\n",
       "        -0.01952049,  0.04168229, -0.02153583, -0.02907694, -0.0420514 ,\n",
       "         0.04549034,  0.00587937,  0.03618604, -0.0236129 , -0.03495177,\n",
       "         0.0091994 ,  0.03392631, -0.03665358,  0.03108261, -0.02084528,\n",
       "        -0.03373479, -0.00706956, -0.02570588,  0.02266008, -0.02969061,\n",
       "         0.02595937,  0.02032509, -0.03592053,  0.01637336, -0.04827378,\n",
       "         0.00764459,  0.01267937, -0.00448838, -0.0325127 , -0.01432237,\n",
       "         0.00160727,  0.03432782, -0.01970552,  0.01249082,  0.01468836,\n",
       "         0.04735121,  0.02259797,  0.03623551, -0.00260303,  0.0366354 ,\n",
       "         0.01479185,  0.0155664 , -0.04474191, -0.02006251,  0.00581194,\n",
       "         0.01952538,  0.02831635,  0.03669049,  0.00672931,  0.00913335,\n",
       "        -0.00223316,  0.00901038,  0.01866506,  0.04346972,  0.00764959,\n",
       "         0.01033017,  0.0409821 , -0.01484726, -0.00455476, -0.02377777,\n",
       "        -0.0215332 , -0.02067644,  0.0035886 , -0.0211627 ,  0.03879642,\n",
       "         0.04559758, -0.04595903, -0.04326691, -0.01134912, -0.00917543,\n",
       "         0.01986353,  0.03098044,  0.01275226,  0.04678649, -0.02802868,\n",
       "        -0.03410622,  0.00540535,  0.00628532,  0.00984391,  0.03186729,\n",
       "         0.04683668,  0.01153338,  0.02733256, -0.02791614, -0.02467622,\n",
       "         0.00906469,  0.0153342 , -0.03887607, -0.04312692,  0.00426116,\n",
       "         0.04921346,  0.02979599, -0.03631207, -0.02175195,  0.01426172,\n",
       "        -0.03755216, -0.00724949, -0.02862892, -0.00825327, -0.02905211,\n",
       "         0.03964726, -0.03609635, -0.04612649, -0.03062508,  0.04731439,\n",
       "         0.03181446,  0.03941695,  0.0222747 ,  0.0406341 ,  0.02655804,\n",
       "        -0.03137461,  0.04743605, -0.04258213,  0.04822705,  0.00250825,\n",
       "         0.03504071,  0.03280984,  0.03816792,  0.04004583, -0.00422833,\n",
       "        -0.00214538, -0.02057733, -0.00049534, -0.01692481, -0.02620867,\n",
       "        -0.04685687,  0.00073973, -0.04951539,  0.00138189, -0.03196437,\n",
       "         0.01526209, -0.02535561,  0.04447925,  0.03282114,  0.02715973,\n",
       "        -0.04646251, -0.00487036, -0.04022205,  0.04160831, -0.04199401,\n",
       "        -0.01563377, -0.04513487,  0.00544341, -0.04899332, -0.00502171,\n",
       "         0.04055027, -0.04766341,  0.00744171, -0.01586037,  0.04484962,\n",
       "        -0.0060848 , -0.03644824, -0.00015423,  0.02194009,  0.01273659,\n",
       "        -0.01225598,  0.01387631, -0.01624237, -0.0034321 ,  0.00502386,\n",
       "        -0.00729952,  0.02679081, -0.04998935, -0.04166021,  0.01380208,\n",
       "        -0.0164511 , -0.02107395, -0.04593343, -0.01402203,  0.04411262]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr[0] == repr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
